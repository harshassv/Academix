{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "1it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "1it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "8it [00:00, 8010.13it/s]\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.84it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelName =  callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000001A1EE62B460> system_prompt=None messages_to_prompt=<function messages_to_prompt at 0x000001A1BF4B2EF0> completion_to_prompt=<function default_completion_to_prompt at 0x000001A1BF551090> output_parser=None pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'> query_wrapper_prompt=None model='gpt-3.5-turbo' temperature=0.1 max_tokens=None logprobs=None top_logprobs=0 additional_kwargs={} max_retries=3 timeout=60.0 default_headers=None reuse_client=True api_key='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' api_base='https://api.openai.com/v1' api_version=''\n",
      "0.44597197\n",
      "I cannot provide a summary of the entire video as the context information provided is in text form, not video content.\n",
      "\n",
      "The model is not confident about the answer and hallucinating\n"
     ]
    }
   ],
   "source": [
    "# if file location is passed then do parsing\n",
    "\n",
    "from pdf_parser import parser\n",
    "from llama_index.core import Document,Settings\n",
    "import nest_asyncio\n",
    "from markdown_parser import markdown_parser\n",
    "from RAG import RAG,RAG_query\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "Settings.chunk_size = 1024\n",
    "\n",
    "# parser('./paper.pdf')\n",
    "\n",
    "current_pfile = r'parsed_pdf.md'\n",
    "\n",
    "with open(current_pfile, 'r', encoding=\"UTF-8\") as f:\n",
    "    parsed_text = f.read()\n",
    "\n",
    "title = parsed_text[parsed_text.find(' '):parsed_text.find('\\n')]\n",
    "\n",
    "title = title.strip()\n",
    "\n",
    "\n",
    "documents = []\n",
    "for para in parsed_text.split('##'):\n",
    "        section = para[:para.find('\\n')].strip()\n",
    "        if section.lower() != 'references':\n",
    "            # print(section , para)\n",
    "            doc = Document(text=para, metadata={\"file_name\": title, \"paper_name\": title, \"section\": section})\n",
    "            documents.append(doc)\n",
    "            # summary_documents.append(doc)\n",
    "\n",
    "\n",
    "# parsed_doc = Document(text=parsed_text,\n",
    "#                             metadata = {\"paper_name\": title, \"file_name\": title})\n",
    "\n",
    "base_nodes, objects = markdown_parser(documents)\n",
    "\n",
    "nodes = base_nodes + objects\n",
    "\n",
    "RAG(nodes)\n",
    "\n",
    "# response = RAG_query('can you summarise the entire Frugal GPT paper')\n",
    "\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
